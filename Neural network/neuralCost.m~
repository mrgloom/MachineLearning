function [J,dJ]=neuralCost(y,x,theta,lambda,network)
	
	m=size(y,1);
	K=size(y,2);
	n=size(x,2);

	L=length(network);
	
	for i=1:m
		a=[1;x(i,:)(:)];
		for l=2:L
			
			theta_prev=getTheta(theta,network,l-1);
			
			a_prev=getA(a,network,l-1);
					
			z=theta_prev*a_prev;
			if l==L
				a_next=[sigmoid(z)];
			else a_next=[1;sigmoid(z)];
			end
			a=[a;a_next];
		end
		if i==1
			h=getA(a,network,L)';
		else h=[h;getA(a,network,L)'];
		end
	end
	
	J=0;
	for i=1:m
		J=J-(1/m)*(y(i,:)'*log(h(i,:))+(1-y(i,:))'*log(1-h(i,:)))+(1/(2*m));	
	end
	
	for l=1:(L-1)	
		theta0=getTheta(theta,network,l)
		J=J+lambda/(2*m)*trace((theta0'*theta0)(2:end,2:end));
	end
	dJ=0;
